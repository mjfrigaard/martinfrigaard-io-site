<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Codex meus vaga</title>
    <link>/</link>
    <description>Recent content on Codex meus vaga</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Tue, 07 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Part 2 - Exploring WW2 flying aces</title>
      <link>/post/exploring-ww2-figher-pilots/</link>
      <pubDate>Tue, 07 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/exploring-ww2-figher-pilots/</guid>
      <description>The WW2 fighter pilot data These data come from the Wikipedia page here, and I went over downloading these data in my previous post.
In this post, I am going to be covering some ggplot2 graphs and theme customization examples. I will also be using the skimr and janitor packages.
Load the packages library(tidyverse) library(magrittr) library(skimr) library(styler)   Download data The data from the previous post have been stored in a Github repo here.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I have eight years of experience working in research, data management, and clinical statistics. I’ve been using R &amp;amp; RStudio for the past five years (but can also use Stata, Microsoft SQL server, and MySQL).
Data Analytics Training: I’m happy to provide your team or organization with any of the following courses:
 Data Programming Toolbox: An intro to Git, Unix, Shell scripting, Git/Github, project organization, Docker, R, and RStudio (a one-day workshop)</description>
    </item>
    
    <item>
      <title>Part 1 - Scraping a Wikipedia table of WW2 flying aces</title>
      <link>/post/ww2-fighter-pilots-scraping-html-tables/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/ww2-fighter-pilots-scraping-html-tables/</guid>
      <description>This post covers how to scrape a Wikipedia table of World War II (WWII) flying aces, store it in an R data frame, and export these data into a comma-separated values (.csv) file.
The data I want to download a table of World War II flying aces from Wikipedia. To do this I will need functions from xml2, rvest, dplyr, stringr, lubridate, and readr.
library(xml2) library(rvest) library(tidyverse) Download html page into object in R First I want to store the web url into a string vector in R.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Wed, 09 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description> First Name  Last Name  E-Mail  City  State AL CA IL      Send   </description>
    </item>
    
  </channel>
</rss>