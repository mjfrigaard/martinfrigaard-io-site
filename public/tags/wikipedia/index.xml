<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>wikipedia on cod3x &amp; err@ta</title>
    <link>/tags/wikipedia/</link>
    <description>Recent content in wikipedia on cod3x &amp; err@ta</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Mon, 13 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/wikipedia/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>World War II Flying Aces - Casualties by country (part 3)</title>
      <link>/post/world-war-ii-flying-aces-casualties-by-country-part-3/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/world-war-ii-flying-aces-casualties-by-country-part-3/</guid>
      <description>@mjfrigaard here to
 This is part 3 of a series looking at World War II flying aces. In part 1, I showed how to download data from a Wikipedia (html) table. Then in part 2, I showed some wrangling techniques with dplyr and janitor, and some exploratory data analysis with inspectdf. We discovered that Germany had the highest average number of aerial victories. In this post we will look at the casualties and survivability of flying aces in WW2.</description>
    </item>
    
    <item>
      <title>World War II Flying Aces - Scraping a Wikipedia table (part 1)</title>
      <link>/post/ww2-fighter-pilots-scraping-html-tables/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/ww2-fighter-pilots-scraping-html-tables/</guid>
      <description>This post covers how to scrape a Wikipedia table of World War II (WWII) flying aces, store it in an R data frame, and export these data into a comma-separated values (.csv) file.
The data I want to download a table of World War II flying aces from Wikipedia. To do this I will need functions from xml2, rvest, dplyr, stringr, lubridate, and readr.
library(xml2) library(rvest) library(tidyverse) Download html page into object in R First I want to store the web url into a string vector in R.</description>
    </item>
    
  </channel>
</rss>